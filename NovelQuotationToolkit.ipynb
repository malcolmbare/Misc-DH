{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f76911d",
   "metadata": {},
   "source": [
    "# Novel Quotation Toolkit\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The code below offers an approach to normalizing and parsing quotations in novels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e41cd",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "1. *Counter* from *collections* is used to turn lists with redunant entries into count dictionaries. (i.e. [\"house\", \"dog\", \"house\"] --> {\"house\":2, \"dog\":1}\n",
    "\n",
    "2. *csv* is used to read and write CSV files.\n",
    "\n",
    "3. *math* is used for the square root function.\n",
    "\n",
    "4. *requests* is used to download files from Project Gutenberg.\n",
    "\n",
    "5. *spacy* is used for Depency Parsing and POS tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "import math\n",
    "import requests\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes txt files from Project Gutenberg, extracts text, and then splits text by newline characters\n",
    "def response2Text(response):\n",
    "    return(response.text.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac244d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Middlemarch\n",
    "middlemarch = response2Text(requests.get(\"https://gutenberg.org/cache/epub/145/pg145.txt\"))\n",
    "\n",
    "#Dracula\n",
    "dracula = response2Text(requests.get(\"https://gutenberg.org/cache/epub/345/pg345.txt\"))\n",
    "\n",
    "#Frankenstein\n",
    "frankenstein = response2Text(requests.get(\"https://gutenberg.org/cache/epub/84/pg84.txt\"))\n",
    "\n",
    "#Jane Eyre\n",
    "janeEyre = response2Text(requests.get(\"https://gutenberg.org/cache/epub/1260/pg1260.txt\"))\n",
    "\n",
    "#Mary Barton\n",
    "maryBarton = response2Text(requests.get(\"https://gutenberg.org/cache/epub/2153/pg2153.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb24bc",
   "metadata": {},
   "source": [
    "## Checking Quote Convention\n",
    "\n",
    "The function below looks at each text and measures the prevalence of each quote character style. It then defines a global variable **quotes** that is referenced for the text.\n",
    "\n",
    "If comparing multiple texts, make sure to check the quote convention for each text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da99a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkQuoteConvention(text):\n",
    "  quoteCountSlant = 0\n",
    "  quoteCountStraight = 0\n",
    "  for i in text:\n",
    "    if i.startswith(\"“\") or i.startswith(\"‘\"):\n",
    "      quoteCountSlant += 1\n",
    "    elif i.startswith(\"\\\"\") or i.startswith(\"\\'\"):\n",
    "      quoteCountStraight += 1\n",
    "  if quoteCountSlant > quoteCountStraight:\n",
    "    print(\"Slant quotes are more prevalent with {0} hits compared to {1} hits\".format(str(quoteCountSlant),str(quoteCountStraight)))\n",
    "    return((\"“\", \"”\"))\n",
    "  else:\n",
    "    print(\"Straight quotes are more prevalent with {0} hits compared to {1} hits\".format(str(quoteCountStraight),str(quoteCountSlant)))\n",
    "    return((\"\\\"\", \"\\\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463189e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkQuoteConvention(janeEyre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a705cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkQuoteConvention(frankenstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkQuoteConvention(middlemarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df355d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set global variable\n",
    "quotes = checkQuoteConvention(middlemarch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff52f64",
   "metadata": {},
   "source": [
    "## Finding Books, Chapters, and More\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7ea5e",
   "metadata": {},
   "source": [
    "### checkDiv Function\n",
    "\n",
    "The checkDiv function looks for headings in a text. If it's successful, it will return a list with indices for each appearance of a search term (called **checkTerm**): i.e. \"chapter\" --> [614, 800...,4326,4599] where each index will correspond to the term: i.e [\"Chapter 1\", \"Chapter 2\"...\"Chapter 56\", \"Chapter The Last\"].\n",
    "\n",
    "The checkDiv function works by trying to match the checkTerm with the first word in every line. Since it's possible for a term like \"chapter\" or \"volume\" to start a line and not be a header, the firstPassFirstTerms list only takes instances where the first character is uppercase. As a secondary precaution, a termCount is used to find the most common formatting of a term across the text. For example, if in firstPassFirstTerms we had [\"LETTER\", \"LETTER\", \"Letter\", \"LETTER\", \"LETTER\", \"LETTER\", \"Letter\"] it would return \"LETTER\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c986d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDiv(checkTerm, text):\n",
    "  firstPass = [i for i in range(len(text)) if text[i].lower().startswith(checkTerm)]\n",
    "  splitTerms = [text[i].split() for i in firstPass]\n",
    "  firstPassFirstTerms =[i[0] for i in splitTerms if i[0][0].isupper()]\n",
    "  if len(firstPassFirstTerms) > 0:\n",
    "      termCount = Counter(firstPassFirstTerms)\n",
    "      commonTerm =max(termCount.keys(), key=lambda key: termCount[key]) \n",
    "      result = [i for i in firstPass if text[i].startswith(commonTerm)]\n",
    "      return(result)\n",
    "  else:\n",
    "      print(checkTerm + \" is not a divider\")\n",
    "      return(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "checkDiv(\"chapter\", frankenstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "checkDiv(\"book\", frankenstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce0fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "checkDiv(\"chapter\", frankenstein)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0c898",
   "metadata": {},
   "source": [
    "### compareDiv Function\n",
    "\n",
    "*Real Life Goal of Function:* See the most prevalent structuring of a text by comparing two candidate terms (called **checkTerm**). Here \"volume\" and \"book\". If neither are prevalent in the text, the function should skip this category entirely and work solely on dividing chapters.\n",
    "\n",
    "\n",
    "**getDivDist** Transforms a list of term indexs [i.e. \"chapter\" --> [614, 800...,4326,4599]] into a list of tuples that measure the start and end of each term: [i.e. [614, 800...,4326,4599] --> [(0,613),(614,799)...(4326,4598)]. In other words if text[614] == \"Chapter 1\" then getDivDist covers the entirety of Chapter 1 (text[614:799]).\n",
    "\n",
    "**checkDivDist** Returns the Standard Deviation of a list of integers. Typically Chapters and Volumes are a similar enough length that they should only deviate by fewer than 1000 characters. (NOTE: this standard deviation isn't being normalized by text length so keep this in mind when comparing different novels/authors)\n",
    "\n",
    "**smallestDivDist** If both candidate terms are valid, the function retuns the one with the smallest standard of deviation. The intution here: i.e. when \"book\" --> [300, 800, 1300,1800,2199] and \"vol\" --> [949,1120,1837] \"book will be preferred.\n",
    "\n",
    "**sanityCheckDiv** Prints the results of **getDivDist** and lets user determine if the convention looks right.\n",
    "\n",
    "**falsify** Returns checkTerm if **sanityCheckDiv** is passed.\n",
    "\n",
    "**compareDiv** This is a \"switch\" function that evaluates both candidate terms and returns either the most prevalent structual term or an \"N/A\" if none of the candidates seem promising\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff47457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDivDist(lst,end):\n",
    "  result= []\n",
    "  for i in range(len(lst)-1):\n",
    "    result.append((lst[i], lst[i+1]-1))\n",
    "  result.append((lst[-1],end))\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92720f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkDivDist(lst):\n",
    "  dist = [i[1]-i[0] for i in lst]\n",
    "  average_dist = sum(dist)/len(dist)\n",
    "  diff_dist = math.sqrt(sum([(i - average_dist) **2 for i in dist]) / len(dist))\n",
    "  return(diff_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smallestDivDist(checkTerm1, checkTerm2, text):\n",
    "  checkTerm1DivDist = checkDivDist(getDivDist(checkDiv(checkTerm1, text),len(text)))\n",
    "  checkTerm2DivDist = checkDivDist(getDivDist(checkDiv(checkTerm2, text),len(text)))\n",
    "  if checkTerm1DivDist < checkTerm2DivDist:\n",
    "    return(checkTerm1)\n",
    "  else:\n",
    "    return(checkTerm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dedcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanityCheckDiv(checkTerm, text):\n",
    "    for i in checkDiv(checkTerm,text):\n",
    "        print(text[i])\n",
    "    result = input(\"Does this look right?(Y/N)\")\n",
    "    if result.upper() == \"Y\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606e31e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def falsify(checkTerm,_bool):\n",
    "    if _bool == True:\n",
    "        return checkTerm\n",
    "    else:\n",
    "        return(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareDiv(checkTerm1, checkTerm2, text):\n",
    "  t1 = checkDiv(checkTerm1, text)\n",
    "  t2 = checkDiv(checkTerm2, text)\n",
    "  if t1 != None and t2 != None:\n",
    "    result = smallestDivDist(checkTerm1, checkTerm2, text)\n",
    "    checker =sanityCheckDiv(result, text)\n",
    "    return(falsify(result,checker))\n",
    "  elif t1 == None and t2 ==None:\n",
    "    return(\"N/A\")\n",
    "  elif t1 == None and t2 != None:\n",
    "    checker = sanityCheckDiv(checkTerm2, text)\n",
    "    return(falsify(checkTerm2,checker))\n",
    "  elif t1 != None and t2 == None:\n",
    "    checker = sanityCheckDiv(checkTerm1, text)\n",
    "    return(falsify(checkTerm1,checker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d9b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "compareDiv(\"book\",\"volume\", middlemarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35863527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "compareDiv(\"book\", \"vol\", janeEyre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "compareDiv(\"book\", \"volume\", janeEyre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b180a1f",
   "metadata": {},
   "source": [
    "## Building Paragraph Structure\n",
    "\n",
    "This section builds to the **findDiv** function, which takes text as input and attempts output a nested dictionary of *Structure*, *Chapter*, and *Paragraph* tuples.\n",
    "\n",
    "**compareDiv**, as described above, is used to determine a novel's *Structure*, which here means whether it's divided into volumes, books or neither.  This yields *strucTerm*, the string that represents predominant, outermost division of the text. [Note: if **compareDiv** fails it will return the first line of the text later on].\n",
    "\n",
    "**checkDiv** is used on both *StructTerm* and \"chapter\" to yield *strucDiv* and *chapDiv*. These are both lists of tuples that show where a *Structure* and a *Chapter* begin and end.\n",
    "\n",
    "**combDiv**  takes the information from *strucDiv* and *chapDiv* to create a nested dictionary {structureTuple{chapterTuple{paragraphTuple}}.\n",
    "\n",
    "**makePara** creates a new paragraph with every line break in a chapter and returns a tuple with index infromation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combDiv(strucDiv, chapDiv, text):\n",
    "  result ={}\n",
    "  if strucDiv == None:\n",
    "    chaps = getDivDist(chapDiv, len(text))\n",
    "    paraChaps = {chap: makePara(chap,text) for chap in chaps}\n",
    "    result[(0,len(text))] = paraChaps\n",
    "    return(result)\n",
    "  else:\n",
    "    strucRange = getDivDist(strucDiv, len(text))\n",
    "    for i in strucRange:\n",
    "        chaps = getDivDist([x for x in chapDiv if x > i[0] and x < i[1]], i[1])\n",
    "        paraChaps = {chap: makePara(chap,text) for chap in chaps}\n",
    "        result[i] = paraChaps\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makePara(chap,text):\n",
    "  result =[]\n",
    "  start = chap[0]\n",
    "  for i in range(chap[0], chap[1]):\n",
    "    if text[i] == \"\":\n",
    "      result.append((start,end))\n",
    "      start = i\n",
    "    else:\n",
    "      end = i\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDiv(text):\n",
    "  strucTerm = compareDiv(\"book\", \"volume\", text)\n",
    "  if strucTerm != \"N/A\":\n",
    "      strucDiv = checkDiv(strucTerm, text)\n",
    "  else:\n",
    "      strucDiv = None\n",
    "  chapDiv = checkDiv(\"chap\", text)\n",
    "  strucChapParaNest = combDiv(strucDiv, chapDiv, text)\n",
    "  return(strucChapParaNest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbeb50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "findDiv(janeEyre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "findDiv(middlemarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f5e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "findDiv(frankenstein)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe3e36",
   "metadata": {},
   "source": [
    "## prepCSV\n",
    "This section shows how to take the nested structure-chapter-paragraph dictionary from the **findDiv** function and create a list of lists that can easily be converted to a CSV\n",
    "\n",
    "**strucRow, chapRow,** and **paraRow** are identical functions apart from **paraRow** not having a children count; each function creates a row the describes 1.) the number of the structure, chapter, or paragraph 2.) the index for where that structure, chapter, or paragraph starts 3.) the index for where that structure, chapter, or paragraph ends and 4.) the number of children a structure or chapter have. Each function returns a list.\n",
    "\n",
    "**allText** uses the indices from these from the **findDiv** function to provide text. I.E. if **findDiv** reads {(213,2000):{{(215:316),...:{(215,:217),...} as [\"Volume I.\", \"Chapter I.\", \"It was the best of times, it was the worst of times\"]\n",
    "\n",
    "**makeHeader** generates a header using the first row of the list.\n",
    "\n",
    "**prepCSV** goes paragraph by paragraph to add a list/row to the list of lists. List cotains results from **strucRow, chapRow, paraRow,** and **allText**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6783779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strucRow(struc, strucCount,stucChapParaNext):\n",
    "  row = []\n",
    "  row.append(strucCount)\n",
    "  row.append(struc[0])\n",
    "  row.append(struc[1]) \n",
    "  row.append(len(stucChapParaNext[struc]))\n",
    "  return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad447fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chapRow(chap, struc, chapCount,stucChapParaNext):\n",
    "  row = []\n",
    "  row.append(chapCount)\n",
    "  row.append(chap[0])\n",
    "  row.append(chap[1])\n",
    "  row.append(len(stucChapParaNext[struc][chap]))\n",
    "  return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60573051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paraRow(para,paraCount):\n",
    "  row = []\n",
    "  row.append(paraCount)\n",
    "  row.append(para[0])\n",
    "  row.append(para[1])\n",
    "  return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c770972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allText(struc, chap, para, text):\n",
    "  row = []\n",
    "  row.append(text[struc[0]])\n",
    "  row.append(text[chap[0]])\n",
    "  row.append(\" \".join(text[para[0]:para[1]+1]).strip())\n",
    "  return(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeHeader():\n",
    "    return([\"sNumber\",\"sStart\", \"sStop\", \"sChildrenCt\", \"cNumber\", \"cStart\", \"cStop\", \"cChildrenCt\", \n",
    "           \"paraNum\" ,\"paraStart\", \"paraStop\", \"strucText\", \"chapText\", \"paraText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a8760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepCSV(stucChapParaNext,text):\n",
    "  result = []\n",
    "  strucCount,chapCount,paraCount = 0,0,0\n",
    "  for struc in stucChapParaNext.keys():\n",
    "    strucCount += 1\n",
    "    for chap in stucChapParaNext[struc].keys():\n",
    "      chapCount += 1\n",
    "      for para in stucChapParaNext[struc][chap]:\n",
    "        paraCount += 1\n",
    "        row = []\n",
    "        row += strucRow(struc, strucCount, stucChapParaNext)\n",
    "        row += chapRow(chap,struc, chapCount, stucChapParaNext)\n",
    "        row += paraRow(para, paraCount)\n",
    "        row += allText(struc, chap, para, text)\n",
    "        result.append(row)\n",
    "      paraCount = 0\n",
    "  result.insert(0, makeHeader())\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ffb1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "prepCSV(findDiv(middlemarch),middlemarch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e6c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "prepCSV(findDiv(frankenstein),frankenstein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf50fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "prepCSV(findDiv(janeEyre),janeEyre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d54be",
   "metadata": {},
   "source": [
    "## Dialogue Metrics (Basic)\n",
    "\n",
    "This function provides basic dialogue metrics as long as a paragraph features at least one start and end quotation mark. It works by going through each paragraph, counting the quotes, and determing if a quote character starts or ends a paragraph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c866eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDialogueMetricsBasic(makeCSVL):\n",
    "    result = makeCSVL\n",
    "    result[0] += [\"quoteCountStart\", \"quoteCountEnd\", \"quoteStart\", \"quoteEnd\"]\n",
    "    for x in result[1:]:\n",
    "        paraText = x[-1]\n",
    "        row = []\n",
    "        row.append(len([i for i in paraText if i == quotes[0]]))\n",
    "        row.append(len([i for i in paraText if i == quotes[1]]))\n",
    "        row.append(paraText.startswith(quotes[0]))\n",
    "        row.append(paraText.endswith(quotes[1]))\n",
    "        if row[0] > 0 and row[1]>0:\n",
    "            x += row\n",
    "        else:\n",
    "            x += [\"N/A\"]*4\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e4713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "janeEyreCSV = prepCSV(findDiv(janeEyre),janeEyre)\n",
    "janeEyreCSV_D = addDialogueMetricsBasic(janeEyreCSV)\n",
    "print(janeEyreCSV_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5dce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "maryBartonCSV = prepCSV(findDiv(maryBarton),maryBarton)\n",
    "maryBartonCSV_D = addDialogueMetricsBasic(maryBartonCSV)\n",
    "print(maryBartonCSV_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "middlemarchCSV = prepCSV(findDiv(middlemarch),middlemarch)\n",
    "middlemarchCSV_D = addDialogueMetricsBasic(middlemarchCSV)\n",
    "print(middlemarchCSV_D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "middlemarchCSV_D[0][-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8842b091",
   "metadata": {},
   "source": [
    "## Dialogue Metrics (Advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecbd88b",
   "metadata": {},
   "source": [
    "This set of functions builds on the previous Dialogue Metrics to parse dialogue in quotes from nearby descriptions.\n",
    "\n",
    "The functions are divided in two parts: Processors and Labelers.\n",
    "\n",
    "### Processors\n",
    "\n",
    "**processPair** and **processAntiPairs** returns lists of lists that provide indexes for where a quote starts and stops and where description starts and stops respectively. For example, processPair(\"'I am hungry for a sandwich,' announced Hester.\") would return [[0:25]] while processAntiPairs would return [[26:43]]\n",
    "\n",
    "**processQuote** would take a paragraph like \"'I am hungry for a sandwich,' announced Hester, 'and you will make it for me'\" and return \"'I am hungry for a sandwich and you will make it for me'\"\n",
    "\n",
    "**processInterjection** uses all three functions about to return three strings and one integery: a white-space concatenated quote returned from **process quote**, a \"\\<SEP>\" concatenated quote from **processPair**, a \"\\<SEP>\" concatenated description from **processAntiPairs**, and a count of the \"\\<SEP>\" tens in the previous string.\n",
    "\n",
    "### Labelers\n",
    "\n",
    "The labeler functions are used to apply rules and labels to specific combinations of quote counts and positions. \n",
    "\n",
    "**advancedMetricsSwitcher** looks at whether a paragraph with a quote starts, ends, both starts and ends, or doesn't start with quote characters. It then routes the paragraph to the appropriate function.\n",
    "\n",
    "**advancedMetricsStart, advancedMetricsEnd, advancedMetricsBoth,** and **advancedMetricsNeither** all use the **processInterjection** function if a paragraph contains more than one start and end quote characters. They apply unique rules, however, if the paragraph has exactly one pair of quotes. For instance, the paragraph \"'She raced to the car'\" would be an example of **advancedMetricsBoth** and would not require the quote be split from description. Conversely, the paragraph \"'She raced to the car,' I told the officer.'\" would be an example of **advanceMetricsStart** and would need a rule to split after the end quotation character.\n",
    "\n",
    "### Other\n",
    "\n",
    "**addDialogueAdvanced** is used exclusively for adding onto the prepCSV file.\n",
    "\n",
    "[Note: the Labeler functions need to be modified to work with text that uses straight quotes]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f143df8",
   "metadata": {},
   "source": [
    "### Processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPair(paraText):\n",
    "  result =[]\n",
    "  resultPair=[]\n",
    "  count = 0\n",
    "  for i in range(len(paraText)):\n",
    "    if paraText[i] == quotes[0]:\n",
    "      count += 1\n",
    "      resultPair.append(i)\n",
    "    if paraText[i] == quotes[1]:\n",
    "      count += 1\n",
    "      resultPair.append(i)\n",
    "    if count == 2:\n",
    "      result.append(resultPair)\n",
    "      resultPair = []\n",
    "      count = 0\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bdda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processAntiPairs(pairs, paraText):\n",
    "  result = []\n",
    "  start = 0\n",
    "  for i in pairs:\n",
    "    antiPair = [start, i[0]-1]\n",
    "    result.append(antiPair)\n",
    "    start = i[1]+1\n",
    "  result.append([start, len(paraText)-1])\n",
    "  if pairs[0][0] == result[0][0]:\n",
    "      result = result[1:]\n",
    "  if result[-1][1] - result[-1][0] <3:\n",
    "      result = result[:-1]\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0924a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processQuote(quoteString):\n",
    "    result =quoteString.replace(quotes[0], \"\").replace(quotes[1], \"\")\n",
    "    result = result.strip()\n",
    "    result = quotes[0] + result + quotes[1]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07589371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processInterjection(row, paraText):\n",
    "    quotePairs = processPair(paraText)\n",
    "    descriptionPairs = processAntiPairs(quotePairs, paraText)\n",
    "    quoteJoined = processQuote(\" \".join([paraText[pair[0]:pair[1]+1] for pair in quotePairs]))\n",
    "    quoteSep = \" <SEP> \".join([paraText[pair[0]:pair[1]+1].strip() for pair in quotePairs])\n",
    "    descriptionSep = \" <SEP> \".join([paraText[pair[0]:pair[1]+1].strip() for pair in descriptionPairs])\n",
    "    return([quoteJoined, quoteSep, descriptionSep, len(descriptionPairs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394a847",
   "metadata": {},
   "source": [
    "### Labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db66a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedMetricsBoth(row, paraText):\n",
    "  if row[0] == 1 and row[1] == 1:\n",
    "    return([\"bothVolley\", paraText, \"N/A\", \"N/A\", 0])\n",
    "  else:\n",
    "    dialogueDescription = processInterjection(row, paraText)\n",
    "    return([\"bothMidInterjection\", dialogueDescription[0], dialogueDescription[1],dialogueDescription[2], dialogueDescription[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac958ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedMetricsStart(row, paraText):\n",
    "  if row[0] == 1 and row[1] == 1:\n",
    "    sep = paraText.index(quotes[1])\n",
    "    return([\"startEngine\", paraText[:sep+1].strip(), \"N/A\", paraText[sep+1:].strip(), 0])\n",
    "  else:\n",
    "    dialogueDescription = processInterjection(row, paraText)\n",
    "    return([\"startInterjection\", dialogueDescription[0], dialogueDescription[1],dialogueDescription[2], dialogueDescription[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16835b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedMetricsEnd(row, paraText):\n",
    "  if row[0] == 1 and row[1] == 1:\n",
    "    sep = paraText.index(quotes[0])\n",
    "    return([\"endCaboose\", paraText[sep:], \"N/A\", paraText[:sep].strip(), 0])\n",
    "  else:\n",
    "    dialogueDescription = processInterjection(row, paraText)\n",
    "    return([\"endInterjection\", dialogueDescription[0], dialogueDescription[1],dialogueDescription[2], dialogueDescription[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808b806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedMetricsNeither(row, paraText):\n",
    "  if row[0] == 1 and row[1] == 1:\n",
    "    start = paraText.index(quotes[0])\n",
    "    end = paraText.index(quotes[1])\n",
    "    return([\"neitherSolo\", paraText[start:end+1], \"N/A\", paraText[:start].strip() + \" \" + paraText[end+1:].strip(), 0])\n",
    "  else:\n",
    "    dialogueDescription = processInterjection(row, paraText)\n",
    "    return([\"neitherInterjection\", dialogueDescription[0], dialogueDescription[1],dialogueDescription[2], dialogueDescription[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7696a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advancedMetricsSwitcher(row, paraText):\n",
    "    \n",
    "  if row[2] == True and row[3] == True:\n",
    "    return(advancedMetricsBoth(row, paraText))\n",
    "  elif row[2] == True and row[3] == False:\n",
    "    return(advancedMetricsStart(row, paraText))\n",
    "  elif row[2] == False and row[3] == True:\n",
    "    return(advancedMetricsEnd(row, paraText)) \n",
    "  else:\n",
    "    return(advancedMetricsNeither(row, paraText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDialogueMetricsAdvanced(makeCSVL_D):\n",
    "    result = makeCSVL_D\n",
    "    result[0] += [\"dLabel\",\"dQuoteConcat\", \"dQuoteSep\", \"dDescriptionSep\", \"dDescriptionCt\"]\n",
    "    for x in result[1:]:\n",
    "        row = x[-4:]\n",
    "        if row[0]!=\"N/A\":\n",
    "            paraText = x[-5]\n",
    "            x += advancedMetricsSwitcher(row,paraText)\n",
    "        else:\n",
    "            x+= [\"N/A\"]*4\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb54aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 1\n",
    "quotes = checkQuoteConvention(middlemarch)\n",
    "middlemarchCSV = prepCSV(findDiv(middlemarch),middlemarch)\n",
    "middlemarchCSV_D = addDialogueMetricsBasic(middlemarchCSV)\n",
    "middlemarchCSV_DA = addDialogueMetricsAdvanced(middlemarchCSV_D)\n",
    "print(middlemarchCSV_DA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2\n",
    "quotes = checkQuoteConvention(frankenstein)\n",
    "frankensteinCSV = prepCSV(findDiv(frankenstein),frankenstein)\n",
    "frankensteinCSV_D = addDialogueMetricsBasic(frankensteinCSV)\n",
    "frankensteinCSV_DA = addDialogueMetricsAdvanced(frankensteinCSV_D)\n",
    "print(frankensteinCSV_DA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62776c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 3\n",
    "quotes = checkQuoteConvention(janeEyre)\n",
    "janeEyreCSV = prepCSV(findDiv(janeEyre),janeEyre)\n",
    "janeEyreCSV_D = addDialogueMetricsBasic(janeEyreCSV)\n",
    "janeEyreCSV_DA = addDialogueMetricsAdvanced(janeEyreCSV_D)\n",
    "print(janeEyreCSV_DA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde9976",
   "metadata": {},
   "source": [
    "## Dialogue Metrics (spaCy)\n",
    "\n",
    "This set of funciton applies POS Tagging and Dependency Parsing to each set of descriptions.\n",
    "\n",
    "**prepareRows** creates a list of 3-item large lists to house NounSubject-Root-DirectObject triads.\n",
    "\n",
    "**checkSubject,checkRoot,** and **checkObject** use spaCy's parsers to check if a token qualifies as a subject, root, or object, respectively.\n",
    "\n",
    "**spacyMetrics** splits each description by its seperator token and then checks each portion for a NounSubject-Root-DirectObject triad.\n",
    "\n",
    "**makeSpacyHeader** looks at the max number of triads in a document and creates enough column titles to accomodate that max.\n",
    "\n",
    "**remediateCSV** adds \"N/A\" placeholders for all rows that do not meet the max number of triads in the document.\n",
    "\n",
    "**addDialogueMetricsSpacy** puts it all together!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareRows(lenSep):\n",
    "  result = [[\"N/A\"]*3]\n",
    "  for i in range(lenSep):\n",
    "    result.append([\"N/A\"]*3)\n",
    "  return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ce5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkSubject(nlpToken):\n",
    "  if nlpToken.dep_ == \"nsubj\":\n",
    "    if nlpToken.pos_ == \"PROPN\":\n",
    "      return(nlpToken.text)\n",
    "    elif nlpToken.pos_ == \"PRON\":\n",
    "      return(nlpToken.text)\n",
    "  else:\n",
    "    return(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkRoot(nlpToken):\n",
    "  if nlpToken.dep_ == \"ROOT\":\n",
    "    return(nlpToken.text)\n",
    "  else:\n",
    "    return(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee26eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkObject(nlpToken):\n",
    "  if nlpToken.dep_ == \"dobj\":\n",
    "    if nlpToken.pos_ == \"PROPN\":\n",
    "      return(nlpToken.text)\n",
    "    elif nlpToken.pos_ == \"PRON\":\n",
    "      return(nlpToken.text)\n",
    "  else:\n",
    "    return(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef14bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacyMetrics(description):\n",
    "  splitDesc = description.split(\"<SEP>\")\n",
    "  result = prepareRows(len(description))\n",
    "  count = 0\n",
    "  for desc in splitDesc:\n",
    "    doc = nlp(desc)\n",
    "    for i in doc:\n",
    "      if result[count][0] == \"N/A\":\n",
    "        result[count][0] = checkSubject(i)\n",
    "      if result[count][1] == \"N/A\":\n",
    "        result[count][1] = checkRoot(i)\n",
    "      if result[count][2] == \"N/A\":\n",
    "        result[count][2] = checkObject(i) \n",
    "    count+=1\n",
    "  result = [i for i in result if i != [\"N/A\"]*3]\n",
    "  return(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb535eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addDialogueMetricsSpacy(makeCSVL_DA):\n",
    "    result = makeCSVL_DA\n",
    "    maxCount = 0\n",
    "    for x in result[1:]:\n",
    "        if x[-2]!=\"N/A\":\n",
    "            description = x[-2]\n",
    "            sDescription = spacyMetrics(description)\n",
    "            if len(sDescription) > maxCount:\n",
    "                maxCount =len(sDescription)\n",
    "            for dobSet in sDescription:\n",
    "                x += dobSet\n",
    "    result[0]+=makeSpacyHeader(maxCount)\n",
    "    result = remediateCSV(result)  \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63900896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSpacyHeader(maxCount):\n",
    "    result = []\n",
    "    for i in range(maxCount):\n",
    "        result.append(\"Subj{0}\".format(str(i)))\n",
    "        result.append(\"Root{0}\".format(str(i)))\n",
    "        result.append(\"Obj{0}\".format(str(i)))\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remediateCSV(result):\n",
    "    maxLen = len(result[0])\n",
    "    for x in result[1:]:\n",
    "        x += [\"N/A\"] * (maxLen - len(x))\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f1c2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example1\n",
    "quotes = checkQuoteConvention(middlemarch)\n",
    "middlemarchCSV = prepCSV(findDiv(middlemarch),middlemarch)\n",
    "middlemarchCSV_D = addDialogueMetricsBasic(middlemarchCSV)\n",
    "middlemarchCSV_DA = addDialogueMetricsAdvanced(middlemarchCSV_D)\n",
    "middlemarchCSV_DAS = addDialogueMetricsSpacy(middlemarchCSV_DA)\n",
    "with open(\"middlemarchLabels.tsv\", 'w') as f:\n",
    "    write = csv.writer(f,delimiter='\\t')\n",
    "    write.writerows(middlemarchCSV_DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8678f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example2\n",
    "quotes = checkQuoteConvention(janeEyre)\n",
    "janeEyreCSV = prepCSV(findDiv(janeEyre),janeEyre)\n",
    "janeEyreCSV_D = addDialogueMetricsBasic(janeEyreCSV)\n",
    "janeEyreCSV_DA = addDialogueMetricsAdvanced(janeEyreCSV_D)\n",
    "janeEyreCSV_DAS = addDialogueMetricsSpacy(janeEyreCSV_DA)\n",
    "with open(\"janeEyreLabels.tsv\", 'w') as f:\n",
    "    write = csv.writer(f,delimiter='\\t')\n",
    "    write.writerows(janeEyreCSV_DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c5a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example3\n",
    "quotes = checkQuoteConvention(maryBarton)\n",
    "maryBartonCSV = prepCSV(findDiv(maryBarton),maryBarton)\n",
    "maryBartonCSV_D = addDialogueMetricsBasic(maryBartonCSV)\n",
    "maryBartonCSV_DA = addDialogueMetricsAdvanced(maryBartonCSV_D)\n",
    "maryBartonCSV_DAS = addDialogueMetricsSpacy(maryBartonCSV_DA)\n",
    "with open(\"maryBartonLabels.tsv\", 'w') as f:\n",
    "    write = csv.writer(f,delimiter='\\t')\n",
    "    write.writerows(maryBartonCSV_DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deaeb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example4\n",
    "quotes = checkQuoteConvention(dracula)\n",
    "draculaCSV = prepCSV(findDiv(dracula),dracula)\n",
    "draculaCSV_D = addDialogueMetricsBasic(draculaCSV)\n",
    "draculaCSV_DA = addDialogueMetricsAdvanced(draculaCSV_D)\n",
    "draculaCSV_DAS = addDialogueMetricsSpacy(draculaCSV_DA)\n",
    "with open(\"draculaLabels.tsv\", 'w') as f:\n",
    "    write = csv.writer(f,delimiter='\\t')\n",
    "    write.writerows(draculaCSV_DAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbecabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example5\n",
    "quotes = checkQuoteConvention(frankenstein)\n",
    "frankensteinCSV = prepCSV(findDiv(frankenstein),frankenstein)\n",
    "frankensteinCSV_D = addDialogueMetricsBasic(frankensteinCSV)\n",
    "frankensteinCSV_DA = addDialogueMetricsAdvanced(frankensteinCSV_D)\n",
    "frankensteinCSV_DAS = addDialogueMetricsSpacy(frankensteinCSV_DA)\n",
    "with open(\"frankensteinLabels.tsv\", 'w') as f:\n",
    "    write = csv.writer(f,delimiter='\\t')\n",
    "    write.writerows(frankensteinCSV_DAS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
